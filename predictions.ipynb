{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_models(path_to_models, labels):\n",
    "    \"\"\"Read model dumps from disk.\"\"\"\n",
    "    \n",
    "    models = {}\n",
    "    for num, path in enumerate(path_to_models):\n",
    "        models[labels[num]] = joblib.load(path) \n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to ref cluster indications.\n",
    "path_target_genes = './../data/test/emQTL_Cluster_genes.txt'\n",
    "path_target_cpgs = './../data/test/emQTL_Clusters_CpGs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indicator labels for classes of reference data.\n",
    "ref_labels = [\n",
    "    'orig_pvalues', 'sel_pvalues','orig_pcc', 'sel_pcc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read experimental data\n",
    "ref_data = {\n",
    "    # NOTE: Transpose to (Cpgs x genes).\n",
    "    ref_labels[0]: pd.read_csv(\n",
    "        './../data/train/orig_pvalues_prep.csv', sep=',', index_col=0\n",
    "    ).T,\n",
    "    ref_labels[1]: pd.read_csv(\n",
    "        './../data/train/sel_pvalues_prep.csv', sep=',', index_col=0\n",
    "    ),\n",
    "    # NOTE: Transpose to (Cpgs x genes).\n",
    "    ref_labels[2]: pd.read_csv(\n",
    "        './../data/train/orig_pcc_prep.csv', sep=',', index_col=0\n",
    "    ).T,\n",
    "    ref_labels[3]: pd.read_csv(\n",
    "        './../data/train/sel_pcc_prep.csv', sep=',', index_col=0\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_skmodels = [\n",
    "    './../model_dumps/sk_orig_prep_pvalues.pkl',\n",
    "    './../model_dumps/sk_sel_prep_pvalues.pkl',\n",
    "    './../model_dumps/sk_orig_prep_pcc.pkl',\n",
    "    './../model_dumps/sk_sel_prep_pcc.pkl',\n",
    "]\n",
    "sk_models = fetch_models(path_to_skmodels, ref_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit selected models to data.\n",
    "for name, model in sk_models.items():\n",
    "    model.fit(ref_data[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Biclusters:\n",
    "    \"\"\"Utility representation of a set of biclusters.\"\"\"\n",
    "\n",
    "    def __init__(self, rows, cols, data):\n",
    "\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.data = data\n",
    "        \n",
    "        # NOTE: Sets attributes.\n",
    "        self._setup()\n",
    "        \n",
    "    @property\n",
    "    def nbiclusters(self):\n",
    "        \n",
    "        return self._nbiclusters\n",
    "    \n",
    "    @nbiclusters.setter\n",
    "    def nbiclusters(self, value):\n",
    "\n",
    "        if np.shape(self.rows)[0] == np.shape(self.cols)[0]:\n",
    "            self._nbiclusters = value\n",
    "        else:\n",
    "            raise RuntimeError('Sample clusters: {}, ref clusters {}'\n",
    "                               ''.format(sample, ref))\n",
    "\n",
    "    def _setup(self):\n",
    "        \n",
    "        self.nrows, self.ncols = np.shape(self.data)\n",
    "        self.nbiclusters = np.shape(self.rows)[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def indicators(self):\n",
    "        \"\"\"Determine coordiantes of row and column indicators\n",
    "        for each bicluster.\n",
    "        \"\"\"\n",
    "\n",
    "        row_idx, col_idx = [], []\n",
    "        for cluster_num in range(self.nbiclusters):\n",
    "\n",
    "            rows_bools = self.rows[cluster_num, :] != 0\n",
    "            cols_bools = self.cols[cluster_num, :] != 0\n",
    "\n",
    "            rows = [index for index, elt in enumerate(rows_bools) if elt]\n",
    "            cols = [index for index, elt in enumerate(cols_bools) if elt]\n",
    "\n",
    "            row_idx.append(rows), col_idx.append(cols)\n",
    "\n",
    "        return row_idx, col_idx\n",
    "\n",
    "    @property\n",
    "    def stats(self):\n",
    "        \"\"\"Compute max, min and std from data points \n",
    "        included in biclusters.\n",
    "        \"\"\"\n",
    "        \n",
    "        row_idx, col_idx = self.indicators \n",
    "        data_size = np.size(self.data)\n",
    "        \n",
    "        stats = {}\n",
    "        for num in range(self.nbiclusters):\n",
    "            \n",
    "            _row_cluster = self.data.values[row_idx[num], :]\n",
    "            cluster = _row_cluster[:, col_idx[num]] \n",
    "            if cluster != []: #len(cluster) > 0:\n",
    "                stats[num] = {\n",
    "                    'max': np.max(cluster),\n",
    "                    'min': np.min(cluster),\n",
    "                    'std': np.std(cluster),\n",
    "                    'rel_size': np.size(cluster) / data_size,\n",
    "                    'zeros': int(np.count_nonzero(cluster==0))\n",
    "                }\n",
    "            else:\n",
    "                pass\n",
    "        df_stats = pd.DataFrame(stats).T\n",
    "        df_stats.index.name = 'num'\n",
    "\n",
    "        return df_stats\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"Assign row and column labels to biclusters.\"\"\"\n",
    "        \n",
    "        cpgs = np.array(self.data.columns, dtype=object)\n",
    "        genes =  np.array(self.data.index, dtype=object)\n",
    "        \n",
    "        row_idx, col_idx = self.indicators\n",
    "        \n",
    "        row_labels, col_labels = [], []\n",
    "        for num in range(self.nbiclusters):\n",
    "            row_labels.append(cpgs[row_idx[num]])\n",
    "            col_labels.append(genes[col_idx[num]])\n",
    "            \n",
    "        return row_labels, col_labels\n",
    "    \n",
    "    def to_disk(self):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bicluster instances tracking detected clusters \n",
    "sk_biclusters = {}\n",
    "for label in ref_labels:\n",
    "    rows = sk_models[label].rows_\n",
    "    cols = sk_models[label].columns_\n",
    "\n",
    "    assert np.shape(rows)[0] == np.shape(cols)[0]\n",
    "\n",
    "    sk_biclusters[label] = Biclusters(\n",
    "        rows=rows, cols=cols, data=ref_data[label]\n",
    "    )\n",
    "\n",
    "# TODO: Fix extarcting labels for each set of clsuters. \n",
    "# Continue with comparing extracted clusters to references.\n",
    "#sk_biclusters[ref_labels[0]].labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bicluster statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_pvalues\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/severinlangberg/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:67: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           max           min  rel_size       std  zeros\n",
      "num                                                    \n",
      "0    73.435290  9.248932e-07  0.349697  5.763812    0.0\n",
      "1    57.268668  3.595124e-06  0.109930  7.197291    0.0\n",
      "2    41.719159  4.404799e-04  0.004168  6.081975    0.0\n",
      "\n",
      "sel_pvalues\n",
      "----------------------------------------\n",
      "           max  min  rel_size       std       zeros\n",
      "num                                                \n",
      "0    73.435290  0.0  0.937659  2.991280  68105907.0\n",
      "1    61.135482  0.0  0.000101  3.547641      7345.0\n",
      "2    49.944542  0.0  0.000098  3.555628      7096.0\n",
      "\n",
      "orig_pcc\n",
      "----------------------------------------\n",
      "          max       min  rel_size       std  zeros\n",
      "num                                               \n",
      "0    0.776622 -0.685308  0.070239  0.212464    0.0\n",
      "1    0.822428 -0.736304  0.211891  0.145858    0.0\n",
      "2    0.852443 -0.738278  0.074169  0.235503    0.0\n",
      "\n",
      "sel_pcc\n",
      "----------------------------------------\n",
      "          max       min  rel_size       std       zeros\n",
      "num                                                    \n",
      "0    0.804678  0.000000  0.001712  0.287271     90641.0\n",
      "1    0.852443 -0.866965  0.846905  0.046072  61851679.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ref_labels:\n",
    "    print('{0}\\n{1}'.format(label, '-' * 40))\n",
    "    print(sk_biclusters[label].stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class References:\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, path_to_cpgs, path_to_genes, num_ref_clusters=2):\n",
    "        \n",
    "        # Read target CpG data.\n",
    "        target_cpgs = {str(num + 1): [] for num in range(num_ref_clusters)}\n",
    "        with open(path_to_cpgs, 'r') as cpgfile:\n",
    "\n",
    "            cpg_contents = cpgfile.read().split('\\n')\n",
    "            # Skip header line.\n",
    "            for row in cpg_contents[1:]:\n",
    "                try:\n",
    "                    value, idx, _ = row.split()\n",
    "                    target_cpgs[idx].append(ast.literal_eval(value))\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "        # Read target gene data.\n",
    "        target_genes = {str(num + 1): [] for num in range(num_ref_clusters)}\n",
    "        with open(path_to_genes, 'r') as genefile:\n",
    "\n",
    "            gene_contents = genefile.read().split('\\n')\n",
    "            # Skip header line.\n",
    "            for row in gene_contents[1:]:\n",
    "                try:\n",
    "                    value, idx = row.split()\n",
    "                    target_genes[idx].append(ast.literal_eval(value))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        return References(cpgs=target_cpgs, genes=target_genes)\n",
    "\n",
    "    def __init__(self, cpgs, genes):\n",
    "\n",
    "        self.cpgs = cpgs\n",
    "        self.genes = genes\n",
    "\n",
    "    @property\n",
    "    def cpgs1(self):\n",
    "\n",
    "        return self.cpgs['1']\n",
    "\n",
    "    @property\n",
    "    def cpgs2(self):\n",
    "\n",
    "        return self.cpgs['2']\n",
    "\n",
    "    @property\n",
    "    def genes1(self):\n",
    "\n",
    "        return self.genes['1']\n",
    "\n",
    "    @property\n",
    "    def genes2(self):\n",
    "\n",
    "        return self.genes['2']\n",
    "\n",
    "    def recovery_score(self, pred):\n",
    "        \"\"\"The fraction of true items among the predicted\n",
    "        items.\"\"\"\n",
    "\n",
    "        return np.isin(pred, true).sum() / np.size(true)\n",
    "\n",
    "    def relevance_score(self, pred):\n",
    "        \"\"\"The fraction of predicted items not among the\n",
    "        true items.\"\"\"\n",
    "\n",
    "        return np.isin(true, pred).sum() / np.size(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference clusters.\n",
    "ref_cls = References.from_files(path_target_cpgs, path_target_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_clusters(preds, refs, targets):\n",
    "\n",
    "    scores = {\n",
    "        'cl1_recovery': [], 'cl1_relevance': [],\n",
    "        'cl2_recovery': [], 'cl2_relevance': [],\n",
    "    }\n",
    "\n",
    "    for num, pred_ids in enumerate(preds):\n",
    "\n",
    "        pred = refs[pred_ids]\n",
    "        true1, true2 = targets['1'], targets['2']\n",
    "        # Frac targets among predicted (true positives).\n",
    "        scores['cl1_recovery'].append(recovery_score(true1, pred))\n",
    "        scores['cl2_recovery'].append(recovery_score(true2, pred))\n",
    "        # Frac detected targets compared to cluster size.\n",
    "        scores['cl1_relevance'].append(relevance_score(true1, pred))\n",
    "        scores['cl2_relevance'].append(relevance_score(true2, pred))\n",
    "\n",
    "    df_scores = pd.DataFrame(scores).T\n",
    "    df_scores.columns = [\n",
    "        'cluster_{}'.format(str(num + 1))\n",
    "        for num in range(np.shape(preds)[0])\n",
    "    ]\n",
    "    df_scores.index = pd.MultiIndex.from_product(\n",
    "        [('cluster1', 'cluster2'), ('recovery', 'relevance')]\n",
    "    )\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect pickled wrapped R models\n",
    "path_to_rmodels = [\n",
    "    './../model_dumps/r_orig_prep_pcc.pkl',\n",
    "    './../model_dumps/r_sel_prep_pvalues.pkl',\n",
    "    './../model_dumps/r_orig_prep_pcc.pkl',\n",
    "    './../model_dumps/r_sel_prep_pcc.pkl',\n",
    "]\n",
    "r_models = fetch_models(path_to_rmodels, ref_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in r_models.items():\n",
    "    # NOTE: Convert <pandas.DataFrame> to <numpy.ndarray>\n",
    "    model.fit(ref_data[name].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Bicluster instances tracking detected clusters \n",
    "r_biclusters = {}\n",
    "for label in ref_labels:\n",
    "    rows = r_models[label].rows_\n",
    "    cols = r_models[label].columns_\n",
    "\n",
    "    assert np.shape(rows)[0] == np.shape(cols)[0]\n",
    "    \n",
    "    r_biclusters[label] = Biclusters(\n",
    "        rows=rows, cols=cols, data=ref_data[label]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bicluster statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_pvalues\n",
      "----------------------------------------\n",
      "          max       min  rel_size       std  zeros\n",
      "num                                               \n",
      "0    2.886458  0.000004  0.001305  0.330803    0.0\n",
      "1    2.651763  0.000014  0.000695  0.334991    0.0\n",
      "\n",
      "sel_pvalues\n",
      "----------------------------------------\n",
      "     max  min  rel_size  std       zeros\n",
      "num                                     \n",
      "0    0.0  0.0  0.471879  0.0  34646520.0\n",
      "1    0.0  0.0  0.067740  0.0   4973617.0\n",
      "\n",
      "orig_pcc\n",
      "----------------------------------------\n",
      "          max       min  rel_size      std  zeros\n",
      "num                                              \n",
      "0    0.852443 -0.866965       1.0  0.32326    0.0\n",
      "\n",
      "sel_pcc\n",
      "----------------------------------------\n",
      "          max       min  rel_size      std       zeros\n",
      "num                                                   \n",
      "0    0.852443 -0.866965       1.0  0.06393  72682896.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ref_labels:\n",
    "    print('{0}\\n{1}'.format(label, '-' * 40))\n",
    "    print(r_biclusters[label].stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: Can be wrapped into loop for multiple predictions.\n",
    "def predict(model, data):\n",
    "    \"\"\"Predict biclusters from a dataset.\"\"\"\n",
    "        \n",
    "    # Fit model to data to determine biclusters.        \n",
    "    model.fit(data)\n",
    "    \n",
    "    # Reconstruct data matrices by sorting data according to\n",
    "    # predicted biclusters.\n",
    "    sorted_col_ids = np.argsort(model.column_labels_)\n",
    "    row_sort_array = data[np.argsort(model.row_labels_)]\n",
    "    return row_sort_array[:, sorted_col_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_graphics(data, title, out_path):\n",
    "    \"\"\"Generate a heatmap and save figure to disk.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(title)\n",
    "    sns.heatmap(\n",
    "        data, robust=True, \n",
    "        cmap=plt.cm.RdBu_r, fmt='f', \n",
    "        vmin=np.min(data), vmax=np.max(data),\n",
    "    )\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: Pass trained models with rows_ and cols_ attribtues.\n",
    "def collect_cluster_members(models, references, ref_data):\n",
    "    \"\"\"Determine biclsuter row and column indicators, and collect\n",
    "    bicluster gene and CpG members.\"\"\"\n",
    "    \n",
    "    # Collect bicluster indicators for each detected bicluster.\n",
    "    biclusters = {}\n",
    "    for name, model in models.items():\n",
    "        biclusters[name] = cluster_indices(\n",
    "            model.rows_, model.columns_\n",
    "        )\n",
    "    # Convert cluster indices to cpG and gene labels.\n",
    "    cluster_members = {}\n",
    "    # For each class of reference data\n",
    "    for data_class in references:\n",
    "        # For each bicluster detected in reference data\n",
    "        cluster_members[data_class] = {}\n",
    "        for cluster_num, bicluster in enumerate(biclusters[data_class]):\n",
    "            # Extract labels by indicator indexing.\n",
    "            cluster_members[data_class][cluster_num] = {\n",
    "                'cpgs': list(ref_data[data_class].index[bicluster[0]]),\n",
    "                'genes': list(ref_data[data_class].columns[bicluster[1]])\n",
    "            }\n",
    "            \n",
    "    return cluster_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preds_to_disk(refs, clusters, model, parent='./../predictions/'):\n",
    "    \"\"\"Generate txt files containing row and column indicators for \n",
    "    detected biclusters associated with different datasets.\"\"\"\n",
    "    \n",
    "    for ref_label in refs:\n",
    "\n",
    "        stem = '{0}_biclusters_{1}.txt'.format(model, ref_label)\n",
    "        with open(os.path.join(parent, stem), 'w') as outfile:   \n",
    "            outfile.write('biclusters_{0}\\n'.format(ref_label))\n",
    "\n",
    "            for cluster_num, coords in clusters[ref_label].items():\n",
    "                outfile.write('cluster_num_{0}\\n'.format(cluster_num))\n",
    "                outfile.write('{0}\\n'.format(coords['cpgs']))\n",
    "                outfile.write('{0}\\n'.format(coords['genes']))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_quality(biclusters):\n",
    "    \"\"\"Compute a metric to determine quality of biclusters.\"\"\"\n",
    "    \n",
    "    #for cluster in biclusters:\n",
    "    #    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_similarity_score(true, pred):\n",
    "    \"\"\"Determines percentage of pred items in true.\"\"\"\n",
    "    \n",
    "    return np.isin(pred, true).sum() / np.size(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_stats(biclusters):\n",
    "    \"\"\"Compute max, min and std for a collection of \n",
    "    biclusters.\"\"\"\n",
    "    \n",
    "    # Collect Statistical \n",
    "    #_cluster_stats = {}\n",
    "    #for name, cluster in biclusters.items():\n",
    "    #    _cluster_stats[num] = {\n",
    "    #        'max': np.max(cluster), \n",
    "    #        'min': np.min(cluster),\n",
    "    #        'std': np.std(cluster)\n",
    "    #}\n",
    "    #df_stats = pd.DataFrame(\n",
    "    #    _cluster_stats, columns=['max', 'min', 'std']\n",
    "    #)\n",
    "    #df_stats.index = list(bicluster.keys())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering reference data\n",
    "\n",
    "Applying the selected biclustering algorithms to the reference data, reconstructing and visualizing the results, selecting the bicluster members and writing the results to disk.\n",
    "\n",
    "### Source: scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruct data matrices by sorting data according to\n",
    "# predicted biclusters.\n",
    "reconstr_data = {}\n",
    "for ref_class in ref_labels:\n",
    "    # Extract fitted model\n",
    "    model = sk_clfs[ref_class]\n",
    "    # Sort reference data\n",
    "    _data = ref_data[ref_class].values\n",
    "    _fit_data = _data[np.argsort(model.row_labels_)]\n",
    "    _sorted_col_ids = np.argsort(model.column_labels_)\n",
    "    reconstr_data[ref_class] = _fit_data[:, _sorted_col_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining Bonferroni corrected p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_graphics(\n",
    "    reconstr_data[ref_labels[0]],\n",
    "    'Biclustering results of preprocessed\\n'\n",
    "    'Bonferroni corrected p-values', \n",
    "    './../predictions/imgs/org_prep_pvalues.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining selected Bonferroni corrected p-values\n",
    "\n",
    "Goal: Try to recreate the clusters and compare the contents to paper results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sk_clfs['sel_pvalues']\n",
    "model.n_clusters = 2\n",
    "\n",
    "reconstr_data = predict(\n",
    "    sk_clfs['sel_pvalues'], \n",
    "    ref_data['sel_pvalues'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_graphics(\n",
    "    reconstr_data,\n",
    "    'Biclustering results of selected preprocessed\\n'\n",
    "    'Bonferroni corrected p-values', \n",
    "    './../../predictions/imgs/sel_prep_pvalues.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_graphics(\n",
    "    reconstr_data[ref_labels[2]],\n",
    "    'Biclustering results of preprocessed\\n'\n",
    "    'Pearson`s correlation coefficients', \n",
    "    './../predictions/imgs/org_prep_pcc.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_graphics(\n",
    "    reconstr_data[ref_labels[3]],\n",
    "    'Biclustering results of selected preprocessed\\n'\n",
    "    'Pearson`s correlation coefficients', \n",
    "    './../predictions/imgs/sel_prep_pcc.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fetch bicluster indicators for each detected bicluster\n",
    "# stored as attributes in fitted models.\n",
    "sk_biclusters_ = {}\n",
    "for name, model in sk_clfs.items():\n",
    "    sk_biclusters_[name] = cluster_indices(\n",
    "        model.rows_, model.columns_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert cluster indices to cpG and gene labels for each class \n",
    "# of reference data, and write results to disk.\n",
    "sk_cluster_members = collect_cluster_members(\n",
    "    sk_clfs, ref_labels, ref_data\n",
    ")\n",
    "preds_to_disk(ref_labels, sk_cluster_members, model='sk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source: R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect pickled R models\n",
    "\n",
    "r_clf_paths = [\n",
    "    './../model_dumps/r_orig_prep_pvalues.pkl',\n",
    "    './../model_dumps/r_sel_prep_pvalues.pkl',\n",
    "    './../model_dumps/r_orig_prep_pcc.pkl',\n",
    "    './../model_dumps/r_sel_prep_pcc.pkl',\n",
    "]\n",
    "\n",
    "r_clfs = collect_clfs(r_clf_paths, ref_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit model to data producing cluster estiamtes.\n",
    "for num, (_, model) in enumerate(r_clfs.items()):\n",
    "    # NOTE: Ref data is <dict> (converting to <ndarray>)\n",
    "    model.fit(list(ref_data.values())[num].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Visualizing results (use R tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert cluster indices to cpG and gene labels for each class \n",
    "# of reference data, and write results to disk.\n",
    "r_cluster_members = collect_cluster_members(\n",
    "    r_clfs, references, ref_data\n",
    ")\n",
    "\n",
    "preds_to_disk(references, r_cluster_members, model='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source: Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Checkout BiBench"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
